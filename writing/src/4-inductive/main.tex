\chapter{Inductive Synthesis of State Machines from Scenarios\label{chapter:inductive-synthesis}}

This chapter presents an inductive approach for synthesizing state machines from scenarios. Section~\ref{section:inductive-objectives-and-approach} characterizes the problem, discusses a few requirements and provides an overview of our solution. Section~\ref{section:inductive-background} provides some required background on grammar induction, the inductive framework on which our techniques are rooted \cite{Gold:1978}. Section~\ref{section:lts-induction-from-mscs} describes a technique for learning LTS models from collections of MSCs. This technique is interactive; the end-user is expected to classify additional scenarios generated by the technique as positive or negative examples of system behavior. In Section~\ref{section:inductive-mutliview-consistency}, fluent, goals and domain properties are injected in the process to enforce inter-model consistency and prune the inductive search space for better performance. Section \ref{section:inductive-from-hMSC} discusses how hMSCs can be used as richer input of the synthesis process. Section \ref{section:inductive-correctness} discusses the correctness of our approach.

\input{src/4-inductive/1-objectives-and-approach}
\input{src/4-inductive/2-grammar-induction-for-lts-synthesis}
\input{src/4-inductive/3-interactive}
\input{src/4-inductive/4-injecting-constraints}
\input{src/4-inductive/5-induction-from-hmsc}
\input{src/4-inductive/6-correctness}
\input{src/4-inductive/7-discussion}

\section*{Summary}

This chapter discussed how grammar induction may be adapted to synthesize LTS state machines from end-user scenarios. The RPNI algorithm provides a basis to inductively generalize scenario behaviors as a system LTS; the latter is then projected on the alphabet of each agent to obtain their state machines.

QSM extends RPNI with an interactive feature where an end-user classifies generated scenarios as positive or negative examples of desired system behavior. This constrains the induction process towards good behavior generalizations. It also allows completing the initial scenario collection with interesting agent interactions that were not initially explored.

QSM and ASM may be constrained through equivalence relations defined on system states. This mechanism was instantiated to prune the induction process with the definition of fluent state variables, models of legacy components, domain properties, and goals. In addition to guaranteeing the consistency of synthesized state machines with other available models, the injection of such knowledge offers better induction performance and reduces the number of user interactions.

Structured forms of scenario descriptions, such as hMSCs, prove useful for large systems. They overcome a common limitation of using scenario collections, namely, the assumption that all scenarios start in the same system state. The induction of agent state machines from structured forms of scenarios led to the ASM algorithm, another extension of RPNI. While our current ASM implementation is rather limited, the chapter showed that the design of an induction algorithm mixing hMSC input, scenario questions, and injection of domain knowledge and goals raises minor issues only.

The transition from RPNI/QSM to ASM raises interesting perspectives for future research. From a grammar induction standpoint, a further extension called ASM$^*$ amounts to consider the generalization of a positive language under the control of a negative one. ASM and ASM$^*$ do not exactly fit in the identification-in-the-limit framework; in particular, the convergence criterion would need to be revisited. From a software engineering standpoint, such work would set a sounder basis for tackling the synthesis of behavior models from structured forms of scenarios and safety properties.
