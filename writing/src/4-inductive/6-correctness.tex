\section{Correctness\label{section:inductive-correctness}}

Proving the correctness of our synthesis approach amounts to show that the synthesized system is consistent with both the scenarios and all domain knowledge taken in input. We discuss proof arguments for the different algorithm settings, starting with the simplest case of RPNI-based synthesis and gradually integrating features such as scenario questions and injection of domain knowledge.

\begin{figure}\centering
\scalebox{.65}{
\includegraphics[trim=3mm 3mm 3mm 3mm, clip]{src/4-inductive/images/synthesis-flow-model}}
\caption{Inductive synthesis steps and products.\label{figure:synthesis-flow-model}} 
\end{figure}

Fig.~\ref{figure:synthesis-flow-model} summarizes our approach by showing used algorithms together with their input/output in terms of behavior models and associated languages. 
\begin{itemize}
\item From scenarios, a system LTS is inferred using either RPNI, QSM or ASM. 
\item LTS hiding and minimization is then used to obtain a canonical state machine for each agent. 
\item From the system view point, the result of our synthesis approach is precisely captured by the composition of those state machines.
\end{itemize}

In this figure and in the following discussions,
\begin{itemize}
\item $Sc = (S^+,S^-)$ denotes the input scenario collection; its positive and negative languages are denoted by $\mathcal{L}^+(Sc)$ and $\mathcal{L}^-(Sc)$, respectively.
\item $\mathcal{L}(\me{System})$ denotes the language captured by the inferred system LTS.
\item $\mathcal{L}(Ag)$ denotes the language of an arbitrary agent $Ag$, as captured by its LTS state machine.
\item $\mathcal{L}(\agentscomposed)$ denotes the language captured by the LTS resulting of the composition of individual agent LTSs.
\end{itemize}

We first restrict our attention to the simplest, non-interactive, RPNI approach. Remember from Section~\ref{subsection:inductive-synthesis-statement} that the specification on our approach requires three conditions to hold on synthesized state machines:
\begin{itemize}
\item The \emph{structural consistency} condition requires input scenarios and synthesized agent state machines to agree on the respective agent interfaces.
\item The \emph{consistent agent view} condition requires each synthesized agent state machine to cover the positive behaviors along the corresponding timeline in the input scenarios.
\begin{align}
\mathcal{L}^+(Sc_{\downarrow Ag}) \subseteq \mathcal{L}(Ag)\mbox{~for each agent $Ag$}\label{proof:consistent-agent-view}
\end{align}
where $Sc_{\downarrow Ag}$ denotes the positive behaviors along $Ag$'s timeline in a scenario collection $Sc = (S^+, S^-)$:
\begin{align}
\mathcal{L}^+(Sc_{\downarrow Ag}) = \bigcup_{P \in S^+} \mathcal{L}(P_{\downarrow Ag})~~\cup~~\bigcup_{N \in S^{-}} \mathcal{L}^{+}(N_{\downarrow Ag})\label{proof:lemma-sc-projection}
\end{align}

This is a a slight generalization of the concept of agent traces along a single scenario timeline $M_{\downarrow Ag}$, introduced in Section~\ref{section:background-scenarios}. Observe that it takes both positive and negative scenarios into account.
\item The \emph{consistent system view} requires the system to cover all positive scenarios and reject all negative ones. 
\begin{align}
&\mathcal{L}^+(Sc) \subseteq \mathcal{L}(\agentscomposed)\label{proof:consistent-system-view-1}\\
&\mathcal{L}^-(Sc) \cap      \mathcal{L}(\agentscomposed) = \emptyset\label{proof:consistent-system-view-2}
\end{align}
\end{itemize}

Section~\ref{subsection:system-lts-consistency} briefly discusses the consistency of the inferred system LTS with the scenarios. This result is then used in Section~\ref{subsection:consistent-agent-view} to show that the decomposition step meets the ``structural consistency'' and the ``consistent agent view'' conditions. The ``consistent system view'' condition is further discussed in Section~\ref{subsection:consistent-system-view}. The discussion is pursued in the presence of scenario questions in Section~\ref{subsection:proof-with-scenario-questions} and with the injection of domain knowledge in Section~\ref{subsection:proof-with-domain-knowledge}. Section~\ref{subsection:correctness-of-asm} closes this section with a discussion about the correctness of ASM.

%%%

\subsection{Consistency of the system LTS\label{subsection:system-lts-consistency}}

This section demonstrates that RPNI yields a system LTS consistent with the input scenario collection. The pseudo code given in Algo.~\ref{QSM} is used, ignoring the scenario questions (lines 5 to 10).

\begin{theorem}
\label{theorem:system-lts-consistency-with-sc}
The system LTS synthesized by RPNI covers all positive scenarios and rejects all negative ones.
\begin{align*}
&\mathcal{L}^+(Sc) \subseteq \mathcal{L}(System)\\
&\mathcal{L}^-(Sc) \cap      \mathcal{L}(System) = \emptyset
\end{align*}

\begin{proof}
This theorem is proven by induction using the following invariant:
\begin{align}
&\mathcal{L}^+(Sc) \subseteq \mathcal{L}(A_i)\label{inv:system-lts-consistency-with-sc-1}\\
&\mathcal{L}^-(Sc) \cap      \mathcal{L}(A_i) = \emptyset\label{inv:system-lts-consistency-with-sc-2}
\end{align}

\begin{description}
\item[Base:] $A_0$ denotes the PTA returned by \emph{Initialize}.

The PTA is the largest DFA accepting the positive language; a precondition states that input scenarios are consistent. Therefore the following conditions hold, entailing the invariant:
\begin{align}
&\mathcal{L}^+(Sc) =    \mathcal{L}(A_0)\\
&\mathcal{L}^-(Sc) \cap \mathcal{L}(A_0) = \emptyset
\end{align}

\item[Inductive step:] $A_i$ is the quotient automaton denoting the current solution at step $i$.

From a solution $A_i$, the next solution $A_{i+1}$ is computed by the \emph{Merge} function (see line 3 in Algo.~\ref{QSM}). The latter computes a quotient automaton. Definition~\ref{definition:quotient-automaton} guarantees that such quotient automaton may only generalize the language of $A_i$. As the condition~(\ref{inv:system-lts-consistency-with-sc-1}) holds for $A_i$, the following condition holds as well:
\begin{align*}
&\mathcal{L}^+(Sc) \subseteq \mathcal{L}(A_i) \subseteq \mathcal{L}(A_{i+1})
\end{align*}

On an other hand, quotient automata are only kept as next solution if consistent with the negative scenarios (see lines 4 and 11). Therefore, the following condition holds when such solution is kept (line 11):
\begin{align*}
&\mathcal{L}^-(Sc) \cap \mathcal{L}(A_{i+1}) = \emptyset
\end{align*}

\end{description}
\end{proof}
\end{theorem}

A detailed proof of the convergence of RPNI towards the canonical target automaton when it receives a characteristic sample can be found in~\cite{Oncina:1993} in the more general case of transducer learning.

%%%

\subsection{Structural consistency and consistent agent view\label{subsection:consistent-agent-view}}

Given the consistency of the system LTS with the positive and negative scenarios, the decomposition step guarantees that the \emph{structural consistency} and the \emph{consistent agent view} both hold.

Structural consistency only requires the LTS hiding step to make use of adequate agent alphabets, as induced from the scenarios themselves or given by a (consistent) structural model. We do not discuss it further. 

For each agent $Ag$, the ``consistent agent view'' condition (\ref{proof:consistent-agent-view}) can be derived from (\ref{proof:consistent-system-view-1}) using the following properties and definitions:
\begin{align}
&\mathcal{L}(X) \subseteq \mathcal{L}(Y) \implies \mathcal{L}(X \setminus I) \subseteq \mathcal{L}(Y \setminus I) \label{proof-agent-consistency-1}\\
&\mathcal{L}^+(Sc_{\downarrow Ag}) = \mathcal{L}^+(Sc \setminus \Sigma_{Ag}^c)\label{proof-agent-consistency-2}\\
&\mathcal{L}(Ag) = \mathcal{L}(System \setminus \Sigma_{Ag}^c)\label{proof-agent-consistency-3}
\end{align}
where $\Sigma_{Ag}^c$ denotes the set of all system events excluding those of $Ag$'s interface.
\begin{itemize}
\item (\ref{proof-agent-consistency-1}) states that behavior inclusion is preserved under LTS hiding; this property follows from material in Section~\ref{subsection:lts-hiding}. 
\item (\ref{proof-agent-consistency-2}) rewrites the left term of (\ref{proof:consistent-agent-view}) in terms of hiding of scenario behaviors\footnote{using an abuse of notation as the hiding operator is defined on LTS, not on scenarios collections.}. It can be derived from (\ref{proof:lemma-sc-projection}) and the definition of $M_{\downarrow Ag}$ (see Section~\ref{subsection:background-positive-scenarios}). 
\item (\ref{proof-agent-consistency-3}) follows from the definition (\ref{definition:decomposition-step}) of decomposition step itself (see Section~\ref{subsection:inductive-synthesis-approach}). 
\end{itemize}

From Theorem~\ref{theorem:system-lts-consistency-with-sc} ensuring the consistency of the system LTS with input scenarios, the following condition is established thanks to (\ref{proof-agent-consistency-1})
\begin{align}
&\mathcal{L}^+(Sc \setminus \Sigma_{Ag}^c) \subseteq \mathcal{L}(System \setminus \Sigma_{Ag}^c)\label{proof:consistent-agent-view-milestone}
\end{align}

The ``consistent agent view'' condition (\ref{proof:consistent-agent-view}) is established by substituing the right terms of (\ref{proof-agent-consistency-2}) and (\ref{proof-agent-consistency-3}) in (\ref{proof:consistent-agent-view-milestone}).

%%%

\subsection{Consistent system view: the problem of implied scenarios\label{subsection:consistent-system-view}}

This section discusses the correctness of the ``consistent system view'' condition. The conditions related to the positive and negative scenarios are discussed in turn.

\begin{theorem}
The synthesized system covers all positive scenarios.
\begin{align*}
&\mathcal{L}^+(Sc) \subseteq \mathcal{L}(\agentscomposed)
\end{align*}

\begin{proof}
This condition results from two main properties of our approach:
\begin{itemize}
\item The synthesized system LTS covers all positive scenario behaviors, as guaranteed by Theorem~\ref{theorem:system-lts-consistency-with-sc}.
\begin{align*}
&\mathcal{L}^+(Sc) \subseteq \mathcal{L}(System)
\end{align*}
\item Projecting the system LTS on agent alphabets and recomposing their LTS afterwards does not restrict behaviors:
\begin{align*}
&\mathcal{L}(\mbox{System}) \subseteq \mathcal{L}(\agentscomposed)
\end{align*}
This latter condition can be derived from the definition of agent languages (\ref{proof-agent-consistency-3}) and properties of LTS hiding and composition operators (see Section~\ref{section:background-state-machines}).
\end{itemize} 

\end{proof}
\end{theorem}

\begin{theorem}
The synthesized system excludes all negatives scenarios.
\begin{align*}
&\mathcal{L}^-(Sc) \cap \mathcal{L}(\agentscomposed) = \emptyset
\end{align*}
\end{theorem}

This theorem would require the composed system to exclude all negative scenarios. Due to the potential presence of implied scenarios, our approach only guarantees the weaker condition given by Theorem~\ref{theorem:system-lts-consistency-with-sc}, namely,
\begin{align*}
&\mathcal{L}^-(Sc) \cap \mathcal{L}(\mbox{System}) = \emptyset
\end{align*}

In other words, the induction algorithm ensures that the system LTS excludes all negative scenarios. This property can however be lost after the decomposition and recomposition steps.

The reason has to be found in the possible occurence of so-called \emph{implied scenarios}. Remember from Section~\ref{subsection:background-hmsc} that implied scenarios may appear when a system is specified globally while implemented component-wise ~\cite{Alur:2000, Uchitel:2004}. In our case, the set of implied scenarios is precisely defined as:
\begin{align*}
\mathcal{L}(\agentscomposed) \setminus \mathcal{L}(\mbox{System})
\end{align*}

When this language is not empty, implied scenarios denote system behaviors that the system LTS does not accept but which are exhibited by the composition of agent LTSs. Implied scenarios appear when, once distributed, the agents lack monitoring abilities to restrict their behavior so as to precisely match the system LTS.

Not all implied scenarios are problematic in practice. In particular, it might happen that all implied scenarios denote desired system behaviors. In that case, the presence of implied scenarios is not problematic and may be seen as the result of a second generalization step due to the decomposition and recomposition of agent LTS. This second generalization step proves useful as it weakens the necessity of having a pure structurally complete scenario collection in the first place.

Negative implied scenarios, that is, counterexamples of desired behaviors, are more problematic. In particular, a behavior trace $t$ could be such that the following conditions hold:
\begin{align}
&t \in \mathcal{L}^-(Sc)\label{implied-1}\\
&t \notin \mathcal{L}(\mbox{System})\label{implied-2}\\
&t \in \mathcal{L}(\agentscomposed)\label{implied-3}
\end{align}
that is, (\ref{implied-1}) $t$ denotes a system behavior explicitly rejected through a negative scenario; it might be a question answered negatively; (\ref{implied-2}) $t$ is correctly rejected by the system LTS; (\ref{implied-3}) $t$ is still be exhibited by the composed system.

In such case, observe the ``consistent system view'' condition is not met as (\ref{proof:consistent-system-view-2}) does not hold. As with other scenario approaches, e.g. \cite{Alur:2000, Uchitel:2004}, our synthesis technique fails to guarantee a consistent system view between scenarios and state machines in presence of negative implied scenarios.

In order to detect such situations, the technique from \cite{Uchitel:2004} could be adapted to enumerate implied scenarios and submit them as additional scenario questions to the user (see Section~\ref{section:related-for-analysis-3}). 

Note that, fixing implied scenario problems requires rethinking the system decomposition into agents and/or refactoring their interfaces. In other words, the root cause of implied scenarios problems has to be found in the structural decomposition of the system, not in the particular technique used to infer state machines from scenarios. 

%%%

\subsection{Correctness in the presence of scenario questions\label{subsection:proof-with-scenario-questions}}

The specification of QSM has been strengthened in Section~\ref{section:lts-induction-from-mscs}. This strengthening required the synthesized system to be consistent with all scenario questions in addition to the initial scenario collection. 

Provided a consistent system LTS is inferred with QSM, the correctness arguments for the \emph{structural consistency} and \emph{consistent agent view} conditions remain unchanged. The discussion about implied scenarios also takes place here. Therefore, we only prove the consistency of the system LTS induced by QSM when scenario questions are taken into account.

\begin{theorem}
The system LTS inferred by QSM is consistent with the scenario collection extended with the answers to all scenario questions.

\begin{proof}
This theorem is proven by induction (cfr. Algo.~\ref{QSM}):
\begin{description}
\item[Base:] The base case captures a QSM run where all scenario questions are answered positively. 

In such case, QSM roughly reduces to RPNI, for which Theorem~\ref{theorem:system-lts-consistency-with-sc} is known to hold. We still need to prove that all scenario questions are thus accepted by the synthesized system LTS. 

Observe that scenarios accepted at line 7 are consistent with the current solution $A_{new}$ (line 4). The system LTS returned by QSM is a quotient automaton of $A_{new}$; Definition \ref{definition:quotient-automaton} therefore ensures that the system LTS accepts those scenarios as well.

\item[Inductive step:] The inductive step captures a run where a rejected scenario yields a tail recursive call (line 10).

The discussion about positively accepted scenarios remains unchanged. The scenario collection is correctly extended (see line 7).

Every time a scenario question is rejected by the oracle, the scenario collection is correctly extended as well (see line 9). Provided the oracle does not make classification errors, as required in preconditions, the scenario collection remains consistent for the tail recursive call taking place at line 10.
\end{description}
\end{proof}
\end{theorem}

%%%

\subsection{Consistency with goals and domain properties\label{subsection:proof-with-domain-knowledge}}

QSM pre- and postconditions have been implicitly strenghtened in Section~\ref{subsection:induction-pruning-with-goals} in order to ensure that the synthesized system does not violate known safety properties. In other words, provided the input scenarios and safety properties are consistent, the following postcondition is required to hold:
\begin{align}
&\mathcal{L}^-(G) \cap \mathcal{L}(\agentscomposed) = \emptyset \mbox{~~for every safety property~G}\label{consistency-of-system-lts-with-goals}
\end{align}

A weaker condition is proven in Theorem~\ref{theorem:system-lts-consistency-with-goals} as implied scenarios may lead to goals being violated after the decomposition and recomposition steps. Lemma~\ref{lemma:qsm-and-tester-prefixes} first provides a useful milestone.

\begin{lemma}
When two states $q$ and $q'$ are considered for merging by QSM, all their prefixes are traces leading to the same state in the tester automaton capturing $\mathcal{L}^-(G)$.\label{lemma:qsm-and-tester-prefixes}
\begin{proof}
We assume the correctness of the joint traversal for annotating the PTA states with their corresponding states in the tester automaton (see Section~\ref{subsection:induction-pruning-with-goals}). QSM only considers the merging of state pairs corresponding to the same state in the tester automaton. The prefixes property thus holds for the first merge considered on the PTA; it is trivially preserved under state merging and therefore holds for every state pair considered from the successive quotient automata.
\end{proof}
\end{lemma}

\begin{theorem}
\label{theorem:system-lts-consistency-with-goals}
The system LTS synthesized by QSM is consistent with available safety properties, that is,
\begin{align*}
&\mathcal{L}^-(G) \cap \mathcal{L}(\emph{System}) = \emptyset \mbox{~~for every safety property~G}
\end{align*}

\begin{proof}
Let $G$ denote a safety property. The proof proceeds by induction on the following loop invariant:
\begin{align*}
\mathcal{L}^-(G) \cap \mathcal{L}(A_i) = \emptyset
\end{align*}

\begin{description}
\item[Base:] $A_0$ denotes the PTA.

The invariant holds for $A_0$ as (a) the preconditions require the scenarios and the goals to be consistent and (b) the PTA does not generalize the positive scenario language.
\begin{align*}
&\mathcal{L}^-(G) \cap \mathcal{L}^+(Sc) = \emptyset\\
&\mathcal{L}(A_0) = \mathcal{L}^+(Sc)
\end{align*}

\item[Inductive step:] Let $A_i$ denote a current solution considered by QSM and suppose that the invariant holds. We show that the invariant holds for $A_{i+1}$, that is, the quotient automaton of $A_i$ obtained by merging a candidate state pair $(q,q')$.

By construction of our constraint mechanism based on equivalent state classes, $q$ and $q'$ correspond to the same state $t$ in the tester automaton capturing $\mathcal{L}^-(G)$ (see Section~\ref{subsection:induction-pruning-with-goals}).

The tester is known to be a canonical automaton, that is, it is minimal and deterministic (see Section~\ref{subsection:background-property-and-tester-automata}). A bijection thus exists between states and accepted trace suffixes\footnote{formally called residual languages} \cite{Hopcroft:1979}. 

Therefore, all accepted traces from $q$ (resp. $q'$) in the current solution $A_i$ are rejected traces from $t$ in the tester automaton. By Lemma~\ref{lemma:qsm-and-tester-prefixes} all prefixes of $q$ in $A_i$ (resp. $q'$) are prefixes of $t$ in the tester. As the invariant holds for $A_i$, their respective suffixes must be disjoint.

When $q$ and $q'$ are merged by QSM, the same lemma guarantees that the suffixes ``gained'' by $q'$ (resp. $q$) do not yield new traces in $A_{i+1}$ that would violate the safety property $G$. In other words, the invariant holds for $A_{i+1}$.
\end{description}
\end{proof}
\end{theorem}

%%%

\subsection{Correctness in the presence of control information\label{subsection:correctness-of-asm}}

The correctness proof for ASM follows the same reasoning as the one presented for RPNI in Theorem~\ref{theorem:system-lts-consistency-with-sc}. Discussions about structural consistent, consistent agent view and implied scenarios remain unchanged. 

\begin{theorem}
The system LTS synthesized by ASM is consistent with the hMSC and the scenario collection taken as input.
\begin{align*}
&[\mathcal{L}(H)   \cup \mathcal{L}^+(Sc)] \subseteq \mathcal{L}(System)\\
&\mathcal{L}^-(Sc) \cap \mathcal{L}(System) = \emptyset
\end{align*}
\begin{proof}
The theorem is proven by induction, using the following invariant:
\begin{align*}
&[\mathcal{L}(H) \cup \mathcal{L}^+(Sc)] \subseteq \mathcal{L}(A_i)\\
&\mathcal{L}^-(Sc) \cap \mathcal{L}(A_i) = \emptyset
\end{align*}

\begin{description}
\item[Base:] $A_0$ denotes the automaton returned by \emph{Initialize}

The \emph{Initialize} function implements the synthesis algorithm detailed in \cite{Uchitel:2003} which does not generalize hMSC behaviors. Moreover, the input hMSC and the positive scenarios are required to be consistent with the negative scenarios. Therefore the following invariant holds:
\begin{align*}
&[\mathcal{L}(H) \cup \mathcal{L}^+(Sc)] = \mathcal{L}(A_0)\\
&\mathcal{L}^-(Sc) \cap \mathcal{L}(A_0) = \emptyset
\end{align*}

\item[Inductive step:]
The main induction loop is similar to the one of RPNI. It considers successive quotient automata, which generalize the language captured by the current solution $A_i$.
\begin{align*}
&[\mathcal{L}(H) \cup \mathcal{L}^+(Sc)] \subseteq \mathcal{L}(A_i) \subseteq \mathcal{L}(A_{i+1})
\end{align*}

As shown in Algo~\ref{ASM}, quotient automata are not kept unless being consistent with the negative scenarios (lines 3 and 4). Therefore, the following condition holds in any case:
\begin{align*}
&\mathcal{L}^-(Sc) \cap \mathcal{L}(A_{i+1}) = \emptyset
\end{align*}

\end{description}
\end{proof}
\end{theorem}

