\section{Interactive LTS synthesis from MSC collections\label{section:lts-induction-from-mscs}}

Algorithm~\ref{QSM} gives the pseudo-code of the \textsc{QSM} algorithm, a Query driven State-Merging LTS induction technique. \textsc{QSM} takes a consistent scenario collection as input and produces a LTS as output. The completion of the initial scenario collection with classified scenarios that are generated during learning is another output of the algorithm. The input collection must contain at least one positive scenario. The synthesized LTS is consistent with the final scenario collection, that is, it covers all its positive scenarios and excludes all negative ones.

\texttt{A note on terminology}~-- The phrasing here induces a loss of generality. As for RPNI, the fact that the scenario collection captures a prefix-closed positive sample implies that the learned language will be prefix-closed as well. Therefore QSM outputs a LTS. However, QSM is not restricted to the learning of prefix-closed languages; it is better regarded as a pure interactive RPNI extension. All results presented here under a software engineering point of view generalize to DFA induction \emph{mutatis mutandis}.--~\texttt{End of Note}

The induction process starts by constructing an initial LTS covering all positive scenarios only. The LTS is then successively generalized under the control of the available negative scenarios and newly generated scenarios classified by the end-user. This generalization is carried out by successively merging well-selected state pairs of the initial LTS. The induction process is such that, at any step, the current LTS is consistent with all positive scenarios and all negative ones, including the interactively classified ones. In the sequel, two states are said compatible for merging (resp. incompatible) if the quotient LTS which results from their merging is consistent (resp. inconsistent) with the current scenario collection.

\begin{algorithm}[H]
{
\textbf{Algorithm} \textsc{QSM}\\
\KwIn{A (non-empty) consistent scenario collection $Sc = (S_+, S_-)$}
\KwOut{A System LTS, consistent with an extended collection}

$A \leftarrow $ {\tt Initialize($Sc$)}\\
\While{$(q,q') \leftarrow $ {\tt ChooseStatePair($A$)}}{
$A_{new} \leftarrow$ {\tt Merge$(A,q,q')$}\\
\If{{\tt Consistent$(A_{new},Sc)$}}{
 \While{$Query \leftarrow $ {\tt GenerateQuery($A,A_{new}$)}}{
   \If{{\tt CheckWithEndUser($Query$)}}{
     $Sc \leftarrow (S_+ \cup \{Query\},~S_-)$
   }\Else{
     $Sc \leftarrow (S_+,~S_- \cup \{Query\})$\\
     \Return{\textsc{QSM}$(Sc)$}
   }
 }
 $A \leftarrow A_{new}$
}
}
\Return{$A,~Sc$}}
\caption{\textsc{QSM}, an interactive state-merging algorithm with membership queries\label{QSM}}
\end{algorithm}

The \texttt{Initialize} function of \textsc{QSM} returns an initial candidate LTS built from the scenario collection. This function computes $\mathcal{L}^+(Sc)$, the set of positive scenario traces, according to the trace semantics defined in Chapter~\ref{chapter:framework}. Those traces are captured through a PTA; because the positive sample is prefix-closed here, this PTA has all accepting states.

Next, pairs of states are iteratively chosen from the current solution according to the \texttt{ChooseStatePair} function. The quotient automaton obtained by merging such states, and possibly some additional states, is computed by the \texttt{Merge} function. The consistency of this quotient automaton is then checked by the \texttt{Consistent} function using available negative scenarios in the collection. 

When consistent, new scenarios are generated through the \texttt{GenerateQuery} function and submitted to the end-user for classification (see section~\ref{QSM:query}). The scenario collection is refined with these scenarios, according to their classification. If all generated scenarios are classified as positive, the quotient automaton becomes the current candidate solution. The process is iterated until no more pair of states can be considered for merging. When a generated scenario is classified as negative, the algorithm is recursively called on the extended scenario collection.

The original RPNI algorithm can be seen as a particular instance of \textsc{QSM} when no query is generated or, equivalently, without the inner \textbf{while} loop. The advantage of \textsc{QSM} is that a finer control of the generalization offered by the state-merging operations can be obtained by validating these generalizations with an oracle. Section~\ref{QSM:merging} describes the general process of merging compatible state pairs while section~\ref{QSM:query} focuses on the generation of queries submitted to the end-user. Section~\ref{BlueFringe} discusses the adaptation of \textsc{QSM} to the Blue-Fringe strategy.

\subsection{Merging compatible state pairs\label{QSM:merging}}

The various functions which control how merging is performed from an initial automaton are described below. 

\begin{description}

\item[Initialize] The \texttt{Initialize} function returns the prefix tree acceptor built for $\mathcal{L}^+(S)$. For recall, this set includes traces from both the positive scenarios and the preconditions of the negative ones. The PTA built from the initial scenario collection in Figure~\ref{Fig:init:scen} is shown on top of Figure~\ref{Fig:algo:steps}. For simplicity, events in these scenarios define a total order. 

\begin{figure}
\centering
\scalebox{.45}{\includegraphics*{src/4-inductive/images/InitScenA}}
\scalebox{.45}{\includegraphics*{src/4-inductive/images/InitScenB}}
\scalebox{.45}{\includegraphics*{src/4-inductive/images/InitScenC}}
\scalebox{.45}{\includegraphics*{src/4-inductive/images/InitScenD}}
\caption{Initial positive and negative scenarios for a train system\label{Fig:init:scen}.}
\end{figure}

\item[ChooseStatePair] The candidate solution is refined by merging well-selected state pairs. The \texttt{ChooseStatePair} function determines which pairs to consider. It relies on the standard order $<$ on strings. Each state of the PTA can be labeled by its unique prefix from the initial state. Since prefixes can be sorted according to that order, the states can be ranked accordingly. For example, the PTA states in Fig.~\ref{Fig:algo:steps} are labeled by their rank according to this order. The algorithm considers states $q$ of the PTA in increasing order. The state pairs considered for merging only involve such state $q$ and any state $q'$ of lower rank. The $q'$ states are considered in increasing order as well. This particular ordering is specific to the original RPNI algorithm.

\item[Merge] The \texttt{Merge} function merges the two states $(q, q')$ selected in order to compute a quotient automaton, that is, to generalize the current set of positive behaviors. In the example of Fig.~\ref{Fig:algo:steps}, we assume that states 0, 1, and 2 were previously determined not to be compatible for merging (through negative scenarios initially submitted or generated scenarios that were rejected by the user). Merging a candidate state pair may produce a non-deterministic LTS. For example, after having merged $q = 3$ and $q' = 0$ in the upper part of Fig.~\ref{Fig:algo:steps}, two transitions labeled \texttt{start} from state 0 lead to states 2 and 6, respectively. In such a case, the \texttt{Merge} function merges states 2 and 6 and, recursively, any further pair of states that introduces non-determinism. 

We call \textsl{merging for determinization} this recursive operation of removing non-determinism. This operation guarantees that the current solution at any step is deterministic. It produces an automaton which may accept a more general language than the one it starts from and, as such, it is not equivalent to the standard algorithm to transform a non deterministic automaton into a deterministic one accepting the same language~\cite{Hopcroft:1979}. The time complexity of merging for determinization is a linear function of the number of states of the automaton it starts from. 

\begin{figure}[H]
\hspace*{-1cm}
\begin{center}
\scalebox{.63}{\includegraphics*{src/4-inductive/images/AlgoSteps}}
\end{center}
\caption{A typical induction step of the \textsc{QSM} algorithm\label{Fig:algo:steps}.}
\end{figure}

When two states are merged, the rank of the resulting state is defined as the lowest rank of the pair; in particular, the rank of the merged state when merging $q$ and $q'$ is defined as the rank of $q'$ by construction. If no compatible merging can be found between $q$ and any of its predecessor states according to $<$, state $q$ is said to be \textsl{consolidated} (in the example, states 0, 1, and 2 are consolidated).

\item[Consistent] The \texttt{Consistent} function checks whether the automaton $A_{new}$ correctly rejects all negative scenarios. As seen in Algorithm~\ref{QSM}, the quotient automaton is discarded by \textsc{QSM} when it is detected not to be consistent.

\end{description}

\subsection{Generating queries submitted to the end-user\label{QSM:query}}

This section describes how membership queries are generated in the \textsc{QSM} algorithm and how the answers provided by the end-user are processed.

\begin{description}

\item[GenerateQuery] When an intermediate solution is consistent with the available scenarios, new scenarios are generated for classification by the end-user as positive or negative. The aim is to avoid poor generalizations of the learned language. The notion of characteristic sample drives the identification of which new scenarios should be generated as queries. 

Recall from section~\ref{subsection:gi-background-rpni} that a sample is characteristic of a language $L$, called here the target language, if it contains enough positive and negative information. On the one hand, the required positive information is the set of short prefixes $Sp(L)$ which form the shortest histories leading to each target DFA state. This positive information must also include all elements of the kernel $N(L)$ which represents all system transitions, that is, all shortest histories followed by any admissible event. If such positive information is available, the target machine can always be derived from the PTA by an appropriate set of merging operations. On the other hand, the negative scenarios provide the necessary information to make incompatible the merging of states which should be kept distinct. A negative scenario which excludes the merging of a state pair $(q, q')$ can be simply made of the shortest history leading to $q'$ followed by any suffix, \textit{i.e.} any valid continuation, from state $q$ as detailed below.

Consider the current solution of our induction algorithm when a pair of states $(q, q')$ is selected for merging. By construction, $q'$ is always a consolidated state at this step of the algorithm; that is, $q'$ is considered to be in $Sp(L)$. State $q$ is always both the root of a tree and the child of a consolidated state. In other words, $q$ is situated at one letter of a consolidated state, that is, $q$ is considered to be in $N(L)$. States $q$ and $q'$ are compatible according to the available negative scenarios; they would be merged by the standard RPNI algorithm. The QSM extension will first confirm or infirm the compatibility of $q$ and $q'$ by generating scenarios to be classified by the end-user. The generated scenarios are constructed as follows.

\begin{figure}[H]
\centering
\scalebox{.5}{\includegraphics*{src/4-inductive/images/GenerateQuestion_bw}}
\caption{A new scenario to be classified by the end-user\label{Fig:generated:question}.}
\end{figure}

Let $A$ denote the current solution, $L(A)$ the language generated by $A$, and $A_{new}$ the quotient automaton computed by the \texttt{Merge} function at some given step. Let $x \in Sp(L)$ and $y \in N(L)$ denote the short prefixes of $q'$ and $q$ in A, respectively. Let $u \in L(A)/y$ denote a suffix of $q$ in $A$. 

A generated scenario is a string $xu$ such that $xu \in L(A_{new})\setminus L(A)$. This string can be further decomposed as $xvw$ such that $xv \in L(A)$. A generated scenario $xu$ is thus constructed as the short prefix of $q'$ concatenated with a suffix of $q$ in the current solution, provided the entire behavior is not yet accepted by $A$. Such scenario is made of two parts: the first part $xv$ is an already accepted behavior whereas the second part $w$ provides a continuation to be checked for acceptance by the end-user. When submitted to the end-user, the generated scenario can always be rephrased as a question: after having executed the first episode ($xv$), can the system continue with the second episode ($w$)? 

Consider the example in Fig.~\ref{Fig:algo:steps} with selected state pair $q=3, q'=0$. As $q'$ is the root of the PTA, its short prefix is the empty string. The suffixes of $q$ here yield one generated question (Fig.~\ref{Fig:generated:question}), which can be rephrased as follows: when having started and stopped the train, can the controller restart it? One can see that the first episode of this scenario in Fig.~\ref{Fig:algo:steps} is already accepted by $A$ whereas the entire behavior is accepted in $A_{new}$.

\item[CheckWithEndUser] When a new scenario is generated, it is submitted as a membership query to the end-user. If the end-user classifies the $Query$ as positive, it is added to the collection of positive scenarios. This addition changes the search space as it extends $S^+$ and consequently the PTA. However, this extension is implicit as the new solution $A_{new}$ is, by construction, also a quotient automaton of this extended PTA. When the $Query$ is classified as negative the induction process is recursively started on the extended scenario collection.

\end{description}

\subsection{Complexity analysis}

The QSM algorithm has a polynomial time complexity in the size of the learning sample $\mathcal{L}^+(Sc)$. An upper bound on the time complexity can be derived as follows.

Let $n\in \mathcal{O}(|| \mathcal{L}^+(Sc) ||)$ denote the number of states of the PTA built from the initial collection of scenarios. For a fixed collection of scenarios, there are ${\cal O}(n^2)$ state pairs which are considered for merging. The \texttt{Merge} and \texttt{Compatible} functions have a time complexity linear in $n$. The \texttt{GenerateQuery} is a side product of the \texttt{Merge} function and does not change its complexity. The function \texttt{CheckWithEndUser} is assumed to run in constant time. Hence, for a fixed scenario collection, the time complexity is the same as for the RPNI algorithm and is upper bounded by ${\cal O}(n^3)$. This bound is obviously not very tight. It assumes that all pairs of states considered by \texttt{ChooseStatePair} appears to be incompatible, which is a very pessimistic assumption. Practical experiments often show that the actual complexity is much closer to the lower bound $\Omega(n)$. 

The global complexity of QSM depends on the number of recursive calls, that is, the number of times a new scenario submitted to the end-user is classified as negative. The way new scenarios are generated by the \texttt{GenerateQuery} function guarantees that the PTA built from the extended scenario collection has at most ${\cal O}(n^2)$ states. During the whole incremental learning process, there is at most one query for each transition in this tree. Consequently, the number of queries is bounded by ${\cal O}(n^2)$.

When QSM received a characteristic sample in the initial scenario collection (or any scenario collection considered when calling it recursively), it is guaranteed that no additional scenario can be classified as negative. It follows that QSM will not be called recursively anymore and stops by returning the target model. 

An experimental study of the actual sample size required to observe the convergence of \textsc{QSM} and the number of queries submitted to the end-user is detailed in Chapter~\ref{chapter:evaluation}.

\subsection{Reducing the number of queries with blue-fringe\label{BlueFringe}}

The order in which states are considered for merging by the \texttt{ChooseStatePair} function described in section~\ref{QSM:merging} follows from the implicit assumption that the current sample is characteristic. Consequently, two states are considered compatible for merging if there is no suffix to distinguish among them. This can lead to a significant number of scenarios being generated to the end-user, to avoid poor generalizations, when the initial sample is sparse and actually not characteristic for the target System LTS. 

To overcome this problem, one can use an optimized strategy known as Blue-Fringe~\cite{Lang:1998}. The difference lies in the way state pairs are considered for merging. The general idea is to early detect incompatible state pairs and, subsequently, first consider state pairs for which compatibility has the highest chance to be confirmed by the user through positive classification. The resulting ``please confirm'' interaction may also appear more appealing to the user.

\begin{figure}
\hspace*{-1cm}
\scalebox{.65}{\includegraphics*{src/4-inductive/images/BlueFringe_bw}}
\vspace*{-.5cm}
\caption{Consolidated states (red) and states on the fringe (blue) in a temporary solution\label{Fig:BlueFringe}.}
\end{figure}

Fig.~\ref{Fig:BlueFringe} gives a typical example of a temporary solution produced by the original algorithm. Three state classes can be distinguished in this LTS. The red states are the consolidated ones (0, 1 and 2 in this example). Outgoing transitions from red states lead to blue states unless the latter have already been labeled as red. Blue states (4 and 5 in this case) form the blue fringe. All other states are white states. 

The original \texttt{ChooseStatePair} function described in section~\ref{QSM:merging} considers the lowest-rank blue state first (state 4 here) for merge with the lowest-rank red state (0). When this choice leads to a compatible quotient automaton, generated scenarios are submitted to the end-user (in this case, a scenario equivalent to the string \texttt{alarm propagated, emergency stop, emergency open}). The above strategy may lead to multiple queries being generated to avoid poor generalization. Moreover, such queries may be non-intuitive for the user, \textit{e.g.} the \texttt{alarm propagated} event is sent to the train controller without having been fired by the \texttt{alarm pressed} event to the sensor.

To select a state pair for merging, the Blue-Fringe strategy evaluates all (red, blue) state pairs first. The \texttt{ChooseStatePair} function now calls the \texttt{Merge} and \texttt{Compatible} functions before selecting the next state pair. If a blue state is found to be incompatible with all current red states, it is immediately promoted to red; the blue fringe is updated accordingly and the process of evaluating all (red, blue) pairs is iterated. When no blue state is found to be incompatible with red states, the most compatible (red, blue) pair is selected for merging. 

For implementing the Blue-Fringe strategy efficiently, it is convenient to update the \texttt{Initialize} so as to build an augmented prefix tree acceptor. Such a PTA not only captures the positive traces from $\mathcal{L}^+(Sc)$ but also the negative ones from $\mathcal{L}^-(Sc)$. The states reached by a negative trace are tagged as error states, for distinguising them from accepting states. The \texttt{Compatible} function is also updated to return a compatibility score instead of a boolean value. The score is defined as $-\infty$ when, in the merging process for determinization, merging the current (red, blue) pair requires some positive accepting state to be merged with an error state; this score indicates an incompatible merging. Otherwise, the compatibility score measures how many states in this process have been merged. The (red, blue) pair with the highest compatibility score is considered first. The strategy can be further refined with a compatibility threshold $\alpha$ as additional input parameter. Two states are considered to be compatible if their compatibility score is above that threshold. This additional parameter controls the level of generalization since increasing $\alpha$ decreases the number of state pairs that are considered compatible for merging; it thus decreases the number of generated queries.

On the simple train example of this paper, the QSM algorithm with the original RPNI state-merging order learns the global LTS correctly by submitting 20 scenarios to the end-user (17 should be rejected and only 3 should be accepted). With the Blue-Fringe strategy, the same LTS is synthesized with only 3 scenarios being submitted (one to be rejected and two to be accepted). Further comparative results are detailed in Chapter~\ref{chapter:evaluation}.
