\section{Stamina setup\label{section:stamina-setup}}

The competition scenario chosen for Stamina is very similar to the one of Abbadingo.

\begin{quotation}\emph{
A learner downloads a training set made of positive and negative strings, and induces a model using her induction technique. The learned model is then used to label strings of a test sample; these labels are submitted to the competition server. The latter scores the submission and provides a binary feedback as to whether the problem is considered broken or not.
}\end{quotation}

While the competition scenario is similar, Stamina differs from Abbadingo in its focus on the complexity of the learning with respect to the alphabet size. It therefore relies on an adapted generation protocol for target automata and samples.

\subsection{Competition grid}

As in Abbadingo, induction problems are classified in a grid. Here, the competition grid is divided into cells of five problems each, where each cell corresponds to a particular combination of sparsity and alphabet size. Table~\ref{stamina:table:problem-grid} shows how the 100 competition problems are distributed over cells. Easier problems (smaller alphabet and larger sample) are toward the upper-left of the table whereas the harder problems (larger alphabet and smaller sample) are toward the bottom-right.

\begin{table}[h]
\begin{center}
\begin{tabular}{c|c c c c}
&\multicolumn{4}{|c}{Sparsity}\\ 
\textbf{$|\Sigma|$} & \textbf{100\%} & \textbf{50\%} & \textbf{25\%} & \textbf{12.5\%}\\
\hline
\textbf{2}  & 1-5   & 6-10  & 11-15 & 16-20 \\
\textbf{5}  & 21-25 & 26-30 & 31-35 & 36-40 \\
\textbf{10} & 41-45 & 46-50 & 51-55 & 56-60 \\
\textbf{20} & 61-65 & 66-70 & 71-75 & 76-80 \\
\textbf{50} & 81-85 & 86-90 & 91-95 & 96-100\\
\end{tabular}
\end{center}
\caption{\label{stamina:table:problem-grid}Grid of 100 problems distributing the induction difficulty along two dimensions: sparsity of the learning sample and alphabet size.}
\end{table}

With respect to Abbadingo, the following similarities and differences should be noted:

\begin{itemize}

\item An increasing size of the alphabet forms a first difficulty dimension, ranging from 2 to 50 letters. The lower bound allows result comparisons with Abbadingo on easiest problems; the upper bound is representative of behavior models found in the literature.

\item In Abbadingo, the varying automaton size is one difficulty dimension (ranging from 64 to 512). In contrast, Stamina considers automata of roughly 50 states only. These automata provide characteristics of behavior models in terms of the variance of their state degree, among other differences (see Section~\ref{subsection:stamina-machines}).

\item The second difficulty dimension is the decreasing size of the training sample; it is similar to Abbadingo. Nevertheless, samples in Stamina are generated ``from the machine'' by a random walk procedure, instead of randomly drawn from all possible strings (see Section~\ref{subsection:stamina-samples}).

\item Instead of an accuracy measure, submissions in Stamina are scored using a \emph{balanced classification rate} (BCR). BCR places an equal emphasis on the accuracy of an inferred model in terms of acceptance of positive sequences and rejection of negative ones. Obtaining a BCR score of at least 99\% is required to consider a problem broken. A cell is broken if its five problems are broken by the same learner (see Section~\ref{subsection:stamina-scoring})

\item Unlike Abbadingo, Stamina allowed one winner only; the latter is the first learning technique to break a hardest cell among those broken during the competition. To adjust the grid and choose cell difficulties, Blue-fringe has been ran and scored on each problem (see Section~\ref{subsection:stamina-baseline}). The adjustement consisted in ensuring that Blue-fringe almost breaks the problems of the very first cell (alphabet of 2 letters and sparsity of 100\%)\footnote{3 of the 5 problems in the cell are broken by Blue-fringe, which obtains a BCR score of 98\% on the two remaining problems} while obtaining a decent score on cells immediately adjacent. An opensource implementation of this baseline algorithm has been made available for download.

\end{itemize}

\subsection{State Machines\label{subsection:stamina-machines}}

For state machine generation, a quick review of software models has been conducted. Observations were made on a small sample of case-study models found in research publications (about 20 systems). State machine models were analyzed in terms of number of states their states, transitions, alphabet sizes, in-/out degree and depth. Although the sample is too small to form any authoritative conclusion, findings can be interpreted as indicative. Based on these observations, Stamina machines were generated using a variant of the Forest-Fire algorithm~\cite{Leskovec2007}. The algorithm has been tuned to generate state machines presenting the following characteristics.
\begin{description}

\item[Number of states] All state machines have approximately 50 states. This is somewhat larger than the conventional state machines identified in the literature; the aim is to ensure that a well-performing technique could scale to infer models for reasonably complex software systems. It has also been decided not to consider state machines of exactly 50 states in order to avoid a strong bias in the benchmark. Automaton sizes actually range from 41 to 59 states. The latter information was not disclosed during the competition.

\item[Accepting state ratio] A roughly equal proportion of accepting and rejecting states has been chosen, a similarity to Abbadingo. States of most behavior models, notably LTS, are accepting states. It has however been decided to keep non-accepting states as well. This keeps our setup sufficiently close to former competitions such as Abbadingo; in particular, it avoids restricting the problem to the inference of prefix-closed regular languages (see Section~\ref{section:background-lts-and-regular-languages}).

\item[Degree distribution] Following observations from the literature, state machines exhibit an important variance of their state degree, especially on largest alphabets. They may also have sink accepting states, that is, states with no outgoing transition.

\item[Determinism and minimality] Following a common setup of regular inference experiments, all Stamina machines are both deterministic and minimal.

\end{description}

\subsection{Training and test samples\label{subsection:stamina-samples}}

Training and test samples were generated using a dedicated generation procedure. This procedure aims at simulating the way examples of system behavior are usually obtained in the software engineering community (e.g. a collection of program traces at implementation level, the generation of scenarios at design level, and so on). Stamina samples present the following characteristics.

\begin{description}

\item[Generated by the target] A dedicated algorithm were implemented to generate positive strings by walking through the automaton. From the initial state it randomly selects outgoing transitions with a uniform distribution. When an accepting state $v$ is reached, the generation ends with a probability of $1.0/(1 + 2*outdegree(v))$. This procedure simulates an ``end-of-string'' transition from state $v$ with half the probability of an existing transition. The length distribution of the strings generated is approximately centered on $5 + depth(automaton)$. As in Abbadingo, this provides a good chance of reaching the deepest state of the automaton. However, no guarantee is given of having a structurally complete sample.

\item[Negative strings] Negative strings were generated by randomly perturbing positive strings. Three kinds of edit operation are considered here: substituting, inserting, or deleting a symbol. The editing position is randomly chosen according to a uniform distribution over the string length. Substitution and insertion also use a uniform distribution over the alphabet. The number of editing operations is chosen according to a Poisson distribution (with a mean of 3); the three editing operations have an equal change of being selected. The randomly edited string is included in the negative sample provided it is indeed rejected by the target machine. Otherwise, it is simply discarded.

\end{description}

The random walk algorithm and perturbation procedure serve as building blocks for the generation of training and test samples for each problem. A set of 20.000 strings is first generated as described above; it contains a roughly equal number of positive and negative strings and contains duplicates. The distinct strings are then equally partitioned into two sets, $S_0$ and $S_1$, taking care of respecting the positive and negative balance in each one.
\begin{itemize}
\item A test sample contains 1500 strings randomly drawn from $S_0$ without replacement. It never contains duplicates in order to avoid favoring repeated strings in the scoring metric.
\item The official training sets are sampled from $S_1$ with different levels of sparsity (100\%, 50\%, 25\%, 12.5\%). They usually contain duplicates, as a consequence of random walk generation from the target machine. 
\item Training and test sets do never intersect.
\end{itemize}

\subsection{Submission and Scoring\label{subsection:stamina-scoring}}

Solutions to Stamina problems must be submitted as binary strings to the competition server. The learner is expected to produce a binary sequence of labels where, for each test string, a ``1'' is added to the sequence if the string is considered to be accepted, a ``0'' otherwise. 

To assess solution accuracy, the sequence is compared with a reference string representing the correct labeling of the test set by the target model. The overlap between the two binary strings is measured through the \emph{balanced classification rate (BCR)}. The harmonic BCR measure was chosen because it places equal emphasis on the accuracy of the inferred model in terms of acceptance of positive sequences and rejection of negative ones. Moreover, it does not require the test set to be balanced in terms of number of positive and negative sequences. 

Harmonic BCR is the harmonic mean of two factors. \emph{Sensitivity} is the proportion of positive matches that are predicted to be positive and \emph{Specificity} is the proportion of true negatives that are predicted to be negative. Usually, BCR is computed as arithmetic mean of sensitivity and specificity; the harmonic mean is preferred here because it favors balance between the two factors. Let $TP$, $FP$, $TN$ and $FN$ denote the sets of true positives, false positives, true negatives and false negatives, respectively. Sensitivity and specificity are defined as follows:

$$Sensitivity=\frac{|TP|}{|TP \cup FN|}$$ 

$$Specificity=\frac{|TN|}{|TN \cup FP|}$$

$$BCR=\frac{2*Sensitivity*Specificity}{Sensitivity + Specificity}$$

A problem is considered broken if the BCR score obtained is greater than or equal to 0.99. As in Abbadingo, hill-climbing is made almost impossible by a binary feedback from the oracle, depending on whether the problem is broken or not. A cell is considered broken if all its five problems are broken. The Stamina website dedicates a private section to each registered participant that provides visual feedback about the performance of her algorithm(s). In this section, problems and cells of the submission grid turn to green when broken.

\subsection{Blue-fringe baseline\label{subsection:stamina-baseline}}

Blue-fringe has been ran on all Stamina problems in order to adjust the grid for feasibility and fix the difficulty level of each cell.

Adjusting the grid is similar in spirit to what has been done for Abbadingo. The idea is to adjust free parameters of the competition design in such a way that a state-of-the-art algorithm, here Blue-fringe, breaks the easiest problems. Adjusted parameters were the sizes of the training and test sets and the average length of the strings with respect to the automaton depth. This trial-and-error process converged with three problems broken in the easiest cell; reasonable scores were also observed for Blue-fringe on the two remaining problems and in adjacent cells.

The performance of the Blue-fringe baseline is summarized in Table~\ref{table:stamina-baseline} and illustrated with convergence curves in Fig.~\ref{stamina:image:bluefringe-performance}. As shown there, the BCR score decreases along each of the two difficulty dimensions; this experimentally confirms the expected effect of an increasing alphabet size on the induction difficulty. 

\begin{table}
\begin{center}
\begin{tabular}{c|c c c c}
&\multicolumn{4}{|c}{\textbf{Sparsity}}\\ 
\textbf{$|\Sigma|$} & \textbf{100\%} & \textbf{50\%} & \textbf{25\%} & \textbf{12.5\%}\\
\hline
\textbf{2}  & 0.99 (1) & 0.95 (1) & 0.67 (3) & 0.66 (3)\\
\textbf{5}  & 0.97 (1) & 0.78 (2) & 0.59 (4) & 0.52 (4)\\
\textbf{10} & 0.93 (1) & 0.64 (3) & 0.51 (4) & 0.50 (4)\\
\textbf{20} & 0.91 (1) & 0.63 (3) & 0.54 (4) & 0.51 (4)\\
\textbf{50} & 0.81 (2) & 0.64 (3) & 0.57 (4) & 0.50 (4)\\
\end{tabular}
\end{center}
\caption{Average BCR of Blue-fringe in each cell; the difficulty level is shown in parenthesis.\label{table:stamina-baseline}}
\end{table}

\begin{table}
\begin{center}
\begin{tabular}{c|c}
Difficulty level & Score\\
\hline
1&$0.9 \leq score \leq 1$\\
2&$0.7 \leq score < 0.9$\\
3&$0.6 \leq score < 0.7$\\
4&$0 \leq score < 0.6$\\
\end{tabular}
\end{center}
\caption{\label{stamina:table:calibration}Calibrating cell difficulties, based on the scores given in Table~\ref{table:stamina-baseline}}
\end{table}

\begin{figure}
\centering\scalebox{.4}{
  \includegraphics*{src/6-stamina/images/bluefringe-performance}}
  \caption{Performance curves of Blue-fringe\label{stamina:image:bluefringe-performance}.}
\end{figure}

Thanks to those scores, the difficulty level of each cell has been calibrated using the rules defined in Table~\ref{stamina:table:calibration}. The notion of cell difficulty proved useful for driving the competition. Indeed, the winner was the first technique to have broken a hardest cell. It is not used anymore since the competition has evolved into an evaluation platform with exact scoring (see Section~\ref{section:stamina-platform}).
