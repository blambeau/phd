\chapter{Discussion and Related Work\label{chapter:discussion}}

The technique from \cite{Uchitel:2003}, presented in section~\ref{subsection:background-hmsc}, can be interpreted as synthesizing agent state machines from a hMSC. However, the technique is entirely deductive; it generates a minimal LTS for each agent, that is, a state machine that precisely captures the agent traces defined in the hMSC. Of course, inter-model consistency rules between the hMSC and generated state machines are respected by construction.  The authors' motivation is to be able to model-check or animate a hMSC specification. In that sense, state machines are not intended to be seen or manipulated directly by the end-user.

In \cite{Uchitel:2004}, Uchitel explains how implied scenarios can be used to validate a hMSC specification, say $H$, with experts. Implied scenarios are all traces in $\mathcal{L}_{arch}(H) \setminus \mathcal{L}_{weak}(H)$, that is, scenarios that are not explicitly described in the hMSC, but that will necessarily be accepted in any system consistent with it. These scenarios are enumerated and submitted for classification as positive or negative by an expert. This allows to semi-automatically check the consistency between the system description given by the hMSC and the system composed of the agent state machines generated by the technique aforementioned \cite{Uchitel:2003}. As a notable side effect, classified scenarios enrich the initial scenario description. However, by definition, an implied scenario classified as negative hurts inter-model consistency, as it should be rejected by the system but could not be. In general, negative implied scenarios are a sign that agents and their interfaces should be refactored. 

A technique for synthesizing goals from a scenario collection is presented in~\cite{Damas:2006}. It consist in decorating MSC timelines with invariants on fluents monitored and controlled by the associated agent. From these invariants, goals are induced that respect two kinds of specification patterns, namely \emph{maintain goals} $\square(P \rightarrow Q)$ and \emph{immediate achieve goals} $\square(P \rightarrow \circ Q)$. Here also, inferred goals are submitted for classification by an expert. Accepted goals enrich the goal model while rejected ones call for enriching the scenario collection with a counter example. Thus, the technique helps enriching a multi-view system description while guaranteeing consistency. As it mostly relies on the availability of fluent invariants, the technique could be extended to infer goals from any annotated LTS, and hence, from agent state machines or a hMSC. 

