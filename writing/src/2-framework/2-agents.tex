\section{Agents, System and their Behavior\label{section:background-agents-system-behaviors}}

A system is commonly admitted to be made of active components, called \emph{agents}, that behave and interact so as to fulfill system goals while restricting their behavior to ensure constraints they are assigned to~\cite{Feather:1987}. Some of them are human agents (the passenger), others are physical or electronic devices (e.g. the doors, the actuators), still others are software components (the automated controller). In addition to the notion of \emph{system}, that encompass all agents, the literature makes use of specific terms to distinguish between certain agents and/or agent aggregations. In~\cite{VanLamsweerde:2009} for example, the \emph{software-to-be} denotes software agent(s) that need to be developed (the automated controller, for example), while other agents compose its \emph{environment}. Another boundary consists in distinguishing the software together with its input and output devices from other agents. This boundary, depicted with a dashed line in Fig.~\ref{image:train-scenario-all-agents}, corresponds to the distinction made by Jackson between the \emph{world} and the \emph{machine}~\cite{Jackson:1995}. In this thesis, we focus on the behavior of a single agent as observed by the other agents with which it interacts (as opposed to its internal implementation). From the former agent perspective, then, the \emph{environment} is made of all these latter agents. 

In the light of the previous paragraph, we clearly need tools to capture single agent behaviors while being able to play with agent boundaries in a flexible manner -- for instance, for ``computing'' the behavior of agent aggregations like the \emph{software environment}, the \emph{machine} or simply, the \emph{system}. For this, we choose to model behaviors and interactions in an event-based framework, where agents communicate via messages that are sent and received simultaneously. Such kind of communication, called \emph{synchronous communication} or simply, \emph{message passing}, is motivated by its simplicity, an important aspect for accessibility to stakeholders involved during the early-design phase of a system. The next section introduces  labeled transition systems (LTS), the kind of model we use to capture agent behaviors. The next one presents operators for composing (and decomposing) them under a \emph{synchronous communication} hypothesis, a manner of capturing the behaviors of multiple interacting agents.

\subsection{Agents as Labeled Transition Systems}

In our framework, the behavior of an agent, say \artifact{Ag}, is modeled by a specific kind of finite state machine, called \emph{labeled transition system} (LTS). This formalism, initially introduced by Keller for reasoning about parallel programs~\cite{Keller:1976}, has since been intensively used for specifying and analyzing concurrent systems, e.g. in~\cite{Milner:1989, Clarke:1989, Magee:1997}. A LTS is made of a set of states and a set of transitions between them (see Fig.~\ref{image:framework-start-stop}). Each transition is depicted with an \emph{event} label -- sometimes called an \emph{action} label; also, a specific state is the \emph{initial state}, designated graphically by an empty arrow in front of it (state 0 in the figure). 

\vspace{0.5cm}
\begin{figure}[H]
\centering\scalebox{0.60}{
  \includegraphics*[clip]{src/2-framework/images/start-stop}}
  \caption{A Labeled Transition System for an \artifact{Engine} agent\label{image:framework-start-stop}.}
\end{figure}

Labeled transition systems come with different flavors in the literature that allows capturing more or less meaning, also resulting in few or numerous semantics subtleties. We stick here with a very simple framework, by restricting our attention to \emph{determinate} agents~\cite{Engelfriet:1985}, that is, agents whose behavior can be modeled using \emph{deterministic} transition systems (see below). While a somewhat restrictive choice in terms of expressiveness --~many approaches arising from process algebra do not restrict to such an hypothesis~-- we argue that it naturally keeps the framework simple and intuitive to use for stakeholders. We now turn to some mathematical definitions that, among others, define the aforementioned terms.

Mathematically, a LTS is defined as a 4-tuple $(Q,\Sigma,\delta,q_{init})$ where $Q$ is a finite set of states, $\Sigma$ is a set of labels called its \emph{alphabet}, $\delta$ is a transition relation $Q \times \Sigma\cup\{\tau\} \times Q$ and $q_{init} \in Q$ is the initial state.

A \emph{deterministic} LTS does not have $\tau$ transitions and has no state with two outgoing transitions having the same label (that is, $(q,l,q_1) \in \delta \wedge (q,l,q_2) \in \delta \implies q_1 = q_2$); otherwise it is \emph{non-deterministic}.

A \emph{terminating} state is one with no outgoing transition; otherwise it is \emph{non-terminating}. A \emph{terminating} LTS has at least one terminating state; otherwise it is \emph{non-terminating}. Note that, as such, the LTS definition does not allow distinguishing between terminating states that model successful termination -- an agent stops running intentionally -- and non-successful termination -- an agent, more often the system as a \emph{composed} agent (see next section), \emph{deadlocks} unintentionally. We will come back to this discussion in section~\ref{section:background-discussion}.

The \emph{alphabet} $\Sigma$ captures the notion of \emph{agent interface}, as a set of event labels that an agent recognizes or, said otherwise, in which the agent \emph{engages} in synchronous communications with its environment. For example, the LTS of Fig.~\ref{image:framework-start-stop} has an alphabet \artifact{$\Sigma=\{start, stop\}$}. Note that labeled transition systems do not distinguish between \emph{sent} and \emph{received} events. This distinction being required when playing with scenarios, we assume that an event label uniquely determines the interacting agents and that this architectural information is available elsewhere (typically, from the scenarios themselves). However, we allow an event label to be shared between more than two agents, but assume that only one of them is the \emph{sender}. By simplicity in the sequel, we denote $\Sigma\cup\{\tau\}$ by $\Sigma_{\tau}$ (an alphabet augmented with the $\tau$ label).

An finite LTS \emph{execution} is a finite sequence of its states separated by labels, i.e. \artifact{$w = \textless q_0,l_0,\ldots,q_{n-1},l_{n-1},q_n \textgreater$} with $q_i \in Q$ and $l_i \in \Sigma_{\tau}$. An execution is valid for a LTS if it denotes an existing path, from the initial state, in the corresponding graph; mathematically, $q_0 = q_{init}$ and $(q_i,l_i,q_{i+1}) \in \delta$ for $0 \leq i < n$. The projection of an execution $w$ over an alphabet $\Sigma$ is denoted by $w|_{\Sigma}$ and is the result of keeping, from $w$, only event labels that belong to $\Sigma$ (in other words, eliminating $q_i$ states and $\tau$ labels). Such a projection is also called a \emph{trace}, that we define now.

A \emph{trace} denotes an element of $\Sigma^*$, that is a finite sequence of event labels \artifact{$t= \textless l_0,\ldots,l_{n} \textgreater$} with $l_i \in \Sigma$. Unlike an execution, a trace never contains $\tau$ labels. A trace $t$ is accepted by a LTS if there exists a valid execution $w$ such that $w|_{\Sigma} = t$. In other words, a trace is \emph{accepted} by a LTS if it denotes an existing path in the corresponding graph from the initial path, but allowing ``in the middle'' silent moves offered by $\tau$ transitions in the non-deterministic case (and hence, possibly, more than one path). Note that, by this definition, a prefix of an accepted trace is also an accepted trace; the empty trace $\lambda$ is therefore always accepted. For example, the LTS of Fig.~\ref{image:framework-start-stop} accepts the trace \artifact{<start stop start>}, and hence \artifact{<start stop>}, but not \artifact{<start start>}. We sometimes use a dot notation $w.l$ to denote the concatenation of a trace $w$ with a label or another trace $l$.

The (maybe infinite) set of traces accepted by a LTS, say $P$, is called its \emph{language} and denoted by $\mathcal{L}(P)$. We naturally extend this notion to the language of an agent. For example, the  \emph{language} of the \artifact{Engine} agent is $\mathcal{L}(\artifact{Engine})=\{\lambda$, \artifact{<start>}, \artifact{<start stop>}, \artifact{<start stop start>}, \ldots $\}$. Actually, as prefixes of accepted traces are also accepted traces, LTS capture the class of \emph{prefix-closed} languages, a subclass of \emph{regular} languages~\cite{Hopcroft:1979}. This result opens the way of applying regular learning for synthesizing LTS, as detailed in chapter~\ref{chapter:inductive-synthesis}.

However, another important notion is the one of LTS \emph{equivalence} that permits answering questions like ``\emph{are agents $Ag_1$ and $Ag_2$ the same in term of their behavior?}''. Many different notions of behavioral equivalence exist in the literature, like \emph{strong} and \emph{observational}  equivalences~\cite{Milner:1989}. Their introduction (in process algebra) is motivated by the need to distinguish between particular process cases as well as being able reason about their correctness (in terms of \emph{deadlock}, for instance), especially when dealing with non-determinism. For details, see e.g.~\cite[chap. 3]{Hoare:1985}, \cite[chap. 4 \& 5]{Milner:1989} or the overview given in~\cite{Fernandez:1991}. Our hypotheses, especially the one of \emph{determinate} agents, allows us to stick with the weakest, yet simplest, notion of LTS equivalence: \emph{trace equivalence}~\cite{Hoare:1985, Engelfriet:1985}. Under the latter, two LTS $P$ and $Q$ are equivalent, denoted by $P \equiv_{tr} Q$, if they accept the same set of traces, in other words, if they define the same language $\mathcal{L}(P) = \mathcal{L}(Q)$. This definition naturally extends to behaviorally equivalent \emph{agents}.

Interestingly enough, under trace equivalence, many results from standard automata theory safely apply to LTS (that is, on can use them while preserving behavior equivalence). We revisit those classical results and other definitions in terms of agents and their behaviors. Section~\ref{section:inductive-background} later summarizes results specific to regular induction, where we need them. 

First, if we consider \emph{determinate} agents exclusively, it does not necessarily mean that we use only \emph{deterministic} LTS. Recall that, by definition, non-determinism naturally arises as soon as one uses $\tau$ transitions, and we sometimes do (see, in particular, the \emph{hiding} operator introduced in the next section). This apparent contradiction resolves naturally in our context. Indeed, given a non-deterministic LTS, it is always possible to find a deterministic one --~hence, without any $\tau$~-- which is trace equivalent~\cite{Hopcroft:1979}.

The notion of equivalence between two LTS can actually be revisited in terms of the states of a single LTS. For this, consider a LTS $P = (Q,\Sigma,\delta,q_{init})$ and an existing transition from its initial state $(q_{init},l,q_2) \in \delta$ with $l \in \Sigma_{\tau}$. It is often convenient to interpret this as the LTS $P$ that \emph{transits} with the label $l$ into the LTS $P' = (Q,\Sigma,\delta,q_{2})$. We denote this by $P \stackrel{l}{\longrightarrow} P'$ (which is also straightforward to generalize to accepted traces $P \stackrel{\textless s \textgreater}{\longrightarrow} P''$).  Observe that $P'$ is in fact the same transition system than $P$, except for the initial state. Now, it might be the case that $P$ and $P'$ are trace equivalent, and more generally, that a trace exists such that $P \equiv_{tr} P''$. If they are, it means that at least two states of the original LTS are trace equivalent, that is, that they ``generate'' the same language. From standard automaton theory, it is however possible to find a deterministic LTS accepting exactly the same set of traces but for which no such two states exist. Moreover, this LTS is minimal in terms of number of states and is unique up to state renumbering~\cite{Gold:1978}.

To sum up, in our framework any LTS $P$ -- being deterministic or not -- has a canonical deterministic and minimal form, up to state renumbering, that preserves behaviors. We denote it by $P^{\Delta}$, where $P$ can actually be a LTS \emph{expression} (that is a LTS ``computed'' by applying LTS operators introduced in the next section). Unless stated otherwise, we consider that agent behaviors are captured by such an LTS, and use standard automaton algorithms from~\cite{Hopcroft:1979} -- when needed -- to remove $\tau$ transitions, determinize and minimize LTS under trace equivalence.

\subsection{System as Agent composition}

If a system is composed of active agents and the behavior of each of these agents is explicitly modeled with an LTS, one can ask what is the behavior of the system itself. We define it through parallel composition~\cite{Hoare:1985}, a setting where agents execute asynchronously but synchronize on shared events. Given a system made of $n$ agents, and the composition operator denoted by~$\parallel$, the system is defined as:

\begin{equation}
System = Ag_1 \parallel \ldots \parallel Ag_n
\end{equation}

As we are mostly interested in agent \emph{behaviors}, we use the binary composition operator $\parallel$ defined on LTS, see e.g.~\cite{Giannakopoulou:1999, Magee:1999}. The operator, which is both commutative and associative (allowing our writing above without ambiguity), computes the interleaving of the traces accepted by the two LTS, under the constraint that they synchronize on shared labels. Let $P = (S_1,\Sigma_1,\delta_1,q_{1})$ and $Q = (S_2,\Sigma_2,\delta_2,q_{2})$ denote two LTS. Then, their composition $P \parallel Q$ is another LTS $(S_1 \times S_2,\Sigma_1\cup\Sigma_2,\delta,(q_1,q_2))$, where $\delta$ is the smallest relation satisfying the following rules:

\begin{center}
\begin{tabular}{cc}
$\frac{\displaystyle P \stackrel{l}{\longrightarrow} P'}{\displaystyle P \parallel Q \stackrel{l}{\longrightarrow} P' \parallel Q}~~l \notin \Sigma_2$ &
$\frac{\displaystyle Q \stackrel{l}{\longrightarrow} Q'}{\displaystyle P \parallel Q \stackrel{l}{\longrightarrow} P \parallel Q'}~~l \notin \Sigma_1$ \\
 & \\
\multicolumn{2}{c}{$\frac{\displaystyle P \stackrel{l}{\longrightarrow} P',~Q \stackrel{l}{\longrightarrow} Q'}{\displaystyle P \parallel Q \stackrel{l}{\longrightarrow} P' \parallel Q'}~~l \neq \tau$} \\
\end{tabular}
\end{center}

As one can see, $P \parallel Q$ is defined on the Cartesian product of the states of $P$ and $Q$, and has its initial state simply defined as $(q_1,q_2)$ in this state space. Rules above define possible transitions from such a state. The first two rules are symmetric and encode the fact that, on non shared labels, one LTS may transit while the other stays in its previous state. As stated, those rules allow individual LTS to move along $\tau$ transitions. The last rule forces the two LTS to transit together on all shared labels but $\tau$. A composed LTS can easily be computed constructively by exploring the state space from its initial state until no new state pair is discovered. The trace semantics of a system composed of $n$ agents whose behavior is modeled with LTSs $Ag_1$ to $Ag_n$ is captured as:

\begin{equation}
\mathcal{L}(System) = \mathcal{L}(Ag_1 \parallel \ldots \parallel Ag_n)
\label{equation:system-composition}
\end{equation}

\subsection{Black-box behavior through \emph{hiding}}

If the notion of agent composition gives a sound interpretation to the notion of \emph{system} and its behavior, it is, in fact, of slightly more general use. Indeed, as explained in the introduction of this section, it makes sense to consider not only the composition of all agents but sometimes the composition of a subset of them that, together, define an interesting boundary in the system considered. Consider the agents depicted in the scenario of Fig.~\ref{image:train-scenario-all-agents} for example. The ``machine vs. world'' boundary can simply be modeled as follows:

\vspace{-0.8cm}
\begin{align*}
Machine &= Controller \parallel Actuators \parallel Sensors \\
World   &= Passenger \parallel Doors \parallel Engine \\
System  &= Machine \parallel World
\end{align*}
\vspace{-0.8cm}

However, as defined above, the $Machine$ agent has an interface -- in terms of the set of events in which it engages -- which is actually too large. A look at the boundary depicted by the dashed line in Fig.~\ref{image:train-scenario-all-agents} clearly shows that some of its events model internal communications -- that is events between agents composing the Machine, like \artifact{start-signal} or \artifact{alarm-signal} -- while the others form the natural interface of the $Machine$ with its environment~--~i.e.~those ``crossing'' the depicted boundary, like \artifact{alarm-pressed} or \artifact{stop}. It is often convenient to enforce this separation between internal and external interfaces, for example to avoid environment agents to synchronize with internal events. In such a case, one would like to model the behavior of the $Machine$ as a black box, that is, in terms of external event labels only.

For this, LTSs come with a simple operator called \emph{hiding}. Hiding of a set of labels $I$ in in a LTS $P = (Q,\Sigma,\delta,q_{init})$ is denoted $P \setminus I$ and defines the LTS $(Q,\Sigma \setminus I,\delta_{hidden},q_{init})$ where $\delta_{hidden}$ is the smallest relation satisfying the rules:

\begin{center}
\begin{tabular}{cc}
$\frac{\displaystyle P \stackrel{l}{\longrightarrow} P'}{\displaystyle P \setminus I \stackrel{l}{\longrightarrow} P' \setminus I}~~l \notin I$ & 
$\frac{\displaystyle P \stackrel{l}{\longrightarrow} P'}{\displaystyle P \setminus I \stackrel{\tau}{\longrightarrow} P' \setminus I}~~l \in I$ \\
\end{tabular}
\end{center}

As one can see, the operator simply makes a set of labels invisible from the environment by replacing them by $\tau$. The resulting LTS is non-deterministic, but results from the previous section ensure that a minimal and deterministic equivalent exists. That is, the LTS of the black-box machine we are actually looking for is the following:

\vspace{-0.8cm}
\begin{align*}
Machine' &= (Machine \setminus Internals)^\Delta
\end{align*}
\vspace{-0.8cm}

\noindent where $Machine$ is the composition between the controller, actuators and sensors given previously and $Internals$ is the set of labels of internal machine events $\{\artifact{start-signal}, \artifact{stop-signal}, \artifact{open-signal}, \artifact{alarm-signal}, \ldots\}$. 

The relation between the traces accepted by $Machine$ and those accepted by $Machine'$ or, in other words, the relation between their language is as defined below. Without surprise, traces accepted by the latter are projections, on the alphabet of the world, of those accepted by the former.

\begin{center}
$\mathcal{L}(Machine') = \{ t'~|~\exists t \in \mathcal{L}(Machine)~such~that~t' = t|_{\Sigma_{World}}\}$
\end{center}

